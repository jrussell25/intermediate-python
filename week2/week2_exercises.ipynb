{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QBio REU Intermediate Python\n",
    "\n",
    "## Week 2 Exercises: Numpy and Matplotlib Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I personally use the following lines to change some matplotlib defaults\n",
    "%config InlineBackend.figure_format = 'retina' #If you have a high res display, render the plots more nicely\n",
    "mpl.rc(\"text\", usetex=False) #if you have Latex set this to true and matplotlib will render labels in latex. \n",
    "                             #This will throw a large inscrutible error if you do not have latex installed\n",
    "mpl.rc(\"font\", family = \"serif\") #Serif font in matplotlib\n",
    "mpl.rc(\"figure\",figsize=(9,6)) #Increase default figure size\n",
    "#mpl.style.use('dark_background') #Use a dark background for matplotlib figures if youre using dark theme\n",
    "#plt.rcParams.update({\"figure.facecolor\": \"111111\", #Match the background color to dark theme notebook\n",
    "#                    \"savefig.facecolor\": \"212121\"}) #Match the background of saved figures to Google Slides Dark Theme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "The softmax funtion takes a vector of real numbers and converts it to a valid probability vector (i.e. a vector whose elements are all positive and sum to 1.) The softmax function is defined as\n",
    "\n",
    "$$ \\text{softmax}(x)_i = \\dfrac{e^{x_i}}{\\sum_j e^{x_j}}$$\n",
    "\n",
    "As a note, some of you might recognize this as the Boltzmann Distribution from thermodynamics where it allows us to convert energies into probabilities. A common data analysis problem is classification where we want to assign each data point to one of K classes. Many classification schemes predict probability of membership in each of the K classes rather than assigning each data point to a single class. Lets imagine that we are using such a classification scheme but I give you an array with shape (N,K) where there are N examples and K classes. Instead of giving you probabilities I've given you \"scores\" or unnormalized probabilities.\n",
    "\n",
    "**Part 1** Using only numpy functions and without writing any for loops, write a softmax function that converts this array into a set of probability vectors.\n",
    "\n",
    "*Hint* Think about what dimension you want to apply the softmax over.\n",
    "\n",
    "*Hint* There is a `scipy` softmax implementation `scipy.special.softmax` which I would encourage you to use in the future but not for this exercise\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = 10*np.random.randn(1000,16) #N=1000 K=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2** \n",
    "\n",
    "Using only numpy functions, compute the most likely class for each datapoint. As a bonus challenge, can you compute the top 3 most likely classes for each datapoint? Can you produce an array that contains the K classes ranked for each example from most likely to least?\n",
    "\n",
    "You'll notice that these can be calculated from either the scores or the probabilities since the softmax function is monotonically increasing. This is one of many reasons that softmax is a nice function for this sort of thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "I've included three files containing the cumulative number of Covid19 cases in 7 states from March 1 - June 30, 2019.* They are\n",
    "\n",
    "- `state_covid.npy` - Cumulative cases in each of the seven states\n",
    "- `state_names.npy` - The names of the seven states in the same order as for the case data\n",
    "- `state_pop.npy` - State population for 2019 as projected by the US Census Bureau\n",
    "\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "-  Load all the data files into numpy arrays\n",
    "-  Make a *nice* plot showing the number of total cases in each state (Dont worry about the x-axis handling dates is doable but more trouble than its worth at this point)\n",
    "\n",
    "\n",
    "\\* I took this date from [Johns Hopkins CSSE Github Page](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series). They have collected a lot of this data and also produced a [particulary good dashboard](https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6) for visualizing it (which I thought was great until it all became too depressing...).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2**\n",
    "- Compute the *per capita* case rate in each state using the states' total populations.\n",
    "- Make a plot similar to the one you made in part 1 showing the per capita case rate over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3**\n",
    "\n",
    "- Many people are more concerned with the daily case rate. To compute this from the cumulative data, we could just subtract each day from the previous one to estimate how many new cases appeared that day. Compute and plot the daily number of cases for each state.\n",
    "- On which day did each state have the most new cases? Don't worry about computing the date just get days since March 1. I did initalize an array of datetimes below if you want to play with it.\n",
    "\n",
    "*Hint* This can be done very easilly with numpy. Do not write a for loop for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = np.arange('2020-03','2020-07', dtype='datetime64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-03-13'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.datetime_as_string(dates[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - The important one!\n",
    "\n",
    "Load some data from your research into numpy arrays. Compute something useful about it (mean, standard deviation, max, some mathematical function). Make an informative plot in matplotlib to show what you're working on. I'd really like a few of you to show these to the group next time so give it a shot!\n",
    "\n",
    "We will discuss these later but there are several other sorts of plots to make in matplotlib such as [histograms](https://matplotlib.org/3.1.1/gallery/statistics/histogram_features.html#sphx-glr-gallery-statistics-histogram-features-py), [bar charts](https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py), [box and violin plots](https://matplotlib.org/3.1.1/gallery/statistics/boxplot_vs_violin.html#sphx-glr-gallery-statistics-boxplot-vs-violin-py), and many more, of which you can [find examples in the gallery](https://matplotlib.org/3.1.1/gallery/index.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
